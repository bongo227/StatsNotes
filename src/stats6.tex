\chapter*{Statistics 6}

\newpage
\section{Experimental Design}

    \newpage
    \subsection{Experimental Design}
        \paragraph{Experimental error}
        Experimental error is the effect of other factors other that those controlled by the experimenter. The standard deviation is one way of measuring the experimental error, since its a measure of the spread of data. To minimize experimental error all factors that are not being investigated should be kept constant and a good experiment design should be used.

        \paragraph{Experimental design}
        The simplest experimental design is a paired comparision were experimental error is reduced bu applying the same treatment to the same subjects or in the same condition i.e. testing two diffrent diets on identical twins thus reducing experimental error due to phcological and biological effects.

        \paragraph{Randomisation}
        The purpose of randomisation is to reduce bias. Were possible the experimenter should remove all likely sources of bias by using random sampling to select an unbiased sample and random processes whenever their is a choise such as which twin is assigned which diet. 

        \paragraph{Blocking}
        Completly randomised design is the process of randomly assigning subjects to treatments and uses one-factor analysis of varience. Randomised block design is the process of spliting subjects in to simular subgroups then randomly assigning those in a subgroups to a treatment. This design is analysed using two factor analysis of variance. Randomised block design is used when another factor (a blocking factor) is thought to an effect on the results. 

        \begin{example}
            {
                In a comparision of the drying times of three different types of wood preservatives A, B and C, samples of each four diffrent woods are availible, W1, W2, W3 and W4. Three experimental designs are suggested.
                \begin{center}
                \begin{tabular}{ccc|ccc|ccc}
                & Design 1 & & & Design 2 & & & Design 3 & \\
                A & B & C & A & B & C & A & B & C \\
                \hline
                W1 & W2 & W3 & W1 & W2 & W1 & W1 & W2 & W3 \\
                W1 & W2 & W3 & W2 & W3 & W3 & W3 & W4 & W2 \\
                W1 & W2 & W3 & W3 & W1 & W2 & W4 & W1 & W4 \\
                &    &    & W4 & W4 & W4 & W2 & W3 & W1 \\
                &    &    & W1 & W2 & W3 &    &    &    \\
                \end{tabular}
                \end{center}
            }

            \begin{step}{State two dissadvantages of design 1}
            \begin{itemize}
            \item Each type of preservative is used on only on type of wood thus it would not be possible to tell if any diffrence found was due to diffrent wood or the preservative (or both).
            \item Wood 4 is not included in the test.
            \end{itemize}
            \end{step}

            \begin{step}{Write down the name of design 3}
            Randomised block design
            \end{step}

            \begin{step}{Name the tecnique used to analyse the results from design 3}
            Two factor analysis of varience
            \end{step}

            \begin{step}{State one advantage of design 3 over design 2}
            Design 2 uses some wood samples multiple times whereas design 3 uses all the samples only once. The comparision for mean drying times may be effected in design 2 by the cobination of wood samples used with each preservative.
            \end{step}

            \begin{step}{Explain how randomisation might be used in the context of design 1, 2 and 3}
            \textbf{Design 1} Allocation of wood to treatment should be carried out by a random process, ensuring the results would not be rigged by selecting a wood for the mosted favored preservative.
            
            \textbf{Design 2} A random process would decide which wood was W1 etc, thus the wood used twice would be selected randomly.

            \textbf{Design 3} Less likely to be effected by bias but the order of carrying out treatments should ideally be determined by a random process. 
            \end{step}
        \end{example}

        \paragraph{Control group}
        If a new treatment is applied to an exprimental group, a control group, which recieves no treatment is needed to measure the effects of the new treatment. This control group should as simular as possible to the exprimental group in order to minimize bias.

        \paragraph{Blind trials}
        The plecbo effect is a well known effect were patients will improve by taking a plecbo drug, a treatment which contains no active ingredient. To show that a new drug is effective many more patients must show improvment than those taking the placbo pill. In a blind trial subjects do not know if they are receiving the treatment or the placbo which help reduce bias from the plecbo effect. 
        
        \paragraph{Double blind trials} Doctors that know a patient is on the active drug may expect patients fare better which may be transmitted onto the patient. A double blind trial is were the subject and the person administrating the treatment knows wether a placebo or active drug was given.

        \paragraph{Triple blind trials} To prevent the bias in the statistical analysis it has been suggested that the statician should also not know which patients took the drug which would be a triple blind trial.

        \begin{example}
        {
            To measure the effectiveness of a drug to relive breathlessness 12 subjects, all susceptible to breathlessness, were admisnistred the drug after one attack of breathlessness and the placebo after a seperate attack. One hour after the attacks an index of breathlessness was obtained for each subject, with the following results

            \begin{center}
            \begin{tabular}{c|c|c}
            Subject & Drug & Placebo \\
            \hline
            1  & 28 & 32 \\
            2  & 31 & 33 \\
            3  & 17 & 23 \\
            4  & 18 & 26 \\
            5  & 31 & 34 \\
            6  & 12 & 17 \\
            7  & 33 & 30 \\
            8  & 18 & 19 \\
            9  & 25 & 23 \\
            10 & 19 & 21 \\
            11 & 17 & 24 \\
            12 & 16 & 49 \\
            \end{tabular}
            \end{center}
        }

        \begin{step}{Explain the role that randomisation could play in carrying out the experiment}
        \begin{itemize}
        \item While it would be impossible to obtain a random sample of all sufferers of breathlessness, a random sample of thoses that are suitable and availible could be desided by a random process.
        \item The order in which each patient takes the placbo and drug should be decided by a random process since the effect of the drug may be diffrent after the placbo (or visa-vera).
        \item Alternativly a random selected group of 6 patients would take the placbo first, and the other group would take the drug first.
        \end{itemize}
        \end{step}

        \begin{step}{Explain the meaning of a blind and of a double blind trial in the context of this expriment}
        In a blind trial the subjects would not know weather they are taking the drug or placbo. In a double blind trial, the doctors that are administrating the drug or placbo and accessing the breathlessness index would also not know weather the subject was taking the drug or placbo.
        \end{step}

        \begin{step}{Making no assumption regarding the distribution of the data, investigate the claim (using 5\% significance level) that the drug significantly reduces the breathlessness index.}
        \end{step}
        $H_0: \text{Population median diffrence} = 0$\\
        $H_1: \text{Population median diffrence} \ne 0$

        \begin{center}
        \begin{tabular}{c|c|c|c}
        Subject & Drug & Placebo & Drug - Placebo \\
        \hline
        1  & 28 & 32 & $-$ \\
        2  & 31 & 33 & $-$ \\
        3  & 17 & 23 & $-$ \\
        4  & 18 & 26 & $-$ \\
        5  & 31 & 34 & $-$ \\
        6  & 12 & 17 & $-$ \\
        7  & 33 & 30 & $+$ \\
        8  & 18 & 19 & $-$ \\
        9  & 25 & 23 & $+$ \\
        10 & 19 & 21 & $-$ \\
        11 & 17 & 24 & $-$ \\
        12 & 16 & 49 & $-$ \\
        \end{tabular}
        \end{center}

        $$
        10^- / 2^+
        $$

        \begin{align*}
        X &\sim B(12, 0.5) \\
        P(X \leq 2) &= P(X < 3) \\
        &= 0.0193
        \end{align*}
        
        Since $0.0193 < 0.05$ reject $H_0$ at the 5\% significance level the drug reduceses breathlessness.

        \end{example}
    
    \newpage
    \subsection{Analysis of paired comparisions}
        Assuming their are two normal populations from which paired samples of size $n$ are taken, with means $\mu_1$ and $\mu_2$, then the diffrence between the pairs will also be normal distributed. Thus a test for $\mu_1 = \mu_2$ is equivilent to $\mu_d = 0$.

        $$
        \bar{D} \sim N\left(\mu_d, \frac{\sigma_d^2}{n}\right)
        $$

        $$
        Z = \dfrac{\bar{D} - \mu_d}{\dfrac{\sigma_d}{\sqrt{n}}} \sim N(0, 1)
        $$
        Let $\bar{D}$ and $S_d^2$ denote the mean and variance of the a sample of n diffrences. Thus
        $$
        \frac{\bar{D} - \mu_d}{\dfrac{S_d}{\sqrt{n}}} \sim t_{n-1}
        $$

        \begin{example}
        {
            A school mathamatics teachers wants to test the effect of a new educational computer package. She selects pairs of students of equal ability and randomly selects one from each pair to join the experimental group (with the others making the control group). The results of a later assesment are as follows:

            \begin{center}
            \begin{tabular}{c|c|c}
            Pair & Control & Experimental \\
            \hline
            1  & 72 & 75 \\
            2  & 82 & 79 \\
            3  & 93 & 84 \\
            4  & 65 & 71 \\
            5  & 76 & 82 \\
            6  & 89 & 91 \\
            7  & 81 & 85 \\
            8  & 58 & 68 \\
            9  & 95 & 90 \\
            10 & 91 & 92 \\
            \end{tabular}
            \end{center}

            Assuming the diffrence in marks are normally distributed, investigate the claim that the computer package inproves students understanding using a 5\% significance level.
        }

        \begin{step}{Hypothesis}
        $H_0: \mu_d = 0$\\
        $H_0: \mu_d > 0$
        \end{step}

        \begin{step}{Test statistic}
        \begin{align*}
        \bar{d} &= 1.5\\
        s_d &= 5.720\\
        t &= \frac{1.5 - 0}{\dfrac{5.720}{\sqrt{10}}}\\
        &= 0.8293
        \end{align*}
        \end{step}

        \begin{step}{Critical value}
        $$t_{10 - 1}(0.95) = 1.833$$
        \end{step}

        \begin{step}{Conclusion}
        $0.8293 < 1.833$ so accept $H_0$, their is no evidence at the 5\% significance level that the computer package improves the students results.
        \end{step}

        \end{example}

\newpage
\section{Analysis of Variance}
ANOVA tests are an extension of F-Tests for tests with more than 2 populations. When dealing with anova tests their are two new terms used:
\paragraph{Factor} A characteristic under consideration, thought to influence the measured observations.
\paragraph{Level} A value of the factor.\\
\\
Consider the following test:
A car magazine wishes to compare the average petrol consumption of three simular models of car and has availible six vehicles of each model. \\
\\
This test has 1 factor (model of car) at 3 levels (3 diffrent models).

    \newpage
    \subsection{One-way ANOVA}
        A one-way ANOVA test is used when their is only 1 factor. The follwing notation and formule are used in the calculation of a one-way ANOVA test:
        \bgroup
        \def\arraystretch{2}
        \begin{center}
        \begin{tabular}{l|c|c}
        Description & Symbol & Value \\
        \hline
        Number of samples/levels & k & \\
        Number of observations in $i^{th}$ sample & $n_i$ & $i = 1, 2, ..., k$ \\
        Total number of observations & $n$ & $\displaystyle\sum_i{n_i}$ \\
        Observation $j$ in $i^{th}$ sample & $x_{ij}$ & $j = 1, 2, ..., n_i$ \\
        Sum of $n_i$ observations in the $i^{th}$ sample & $T_i$ & $\displaystyle\sum_j{x_{ij}}$ \\
        Sum of all n observations & $T$ & $\displaystyle\sum_i{T_i}$ \\
        \hline
        Total sum of squares & $SS_T$ & $\displaystyle\sum_i{\displaystyle\sum_j{x_{ij}^2}} - \frac{T^2}{n}$ \\
        Between samples sum of squares & $SS_B$ & $\displaystyle\sum_i{\frac{T_i}{n_i}} - \frac{T^2}{n}$ \\
        Within samples sum of squares & $SS_W$ & $SS_T - SS_B$ \\
        \hline
        Between samples mean squares & $MS_B$ & $\displaystyle\frac{SS_B}{k - 1}$ \\
        Within samples mean squares& $MS_W$ & $\displaystyle\frac{SS_W}{n - k}$ \\
        Total mean squares & $MS_T$ & $\displaystyle\frac{SS_T}{n - 1}$ \\
        \end{tabular}
        \end{center}
        \egroup

        \noindent
        Its convient to lay out an ANOVA test in a table such as:
        \bgroup
        \def\arraystretch{2}
        \begin{center}
        \begin{tabular}{l|c|c|c|c}
        Source of variation & Sum of squares    & Degrees of freedom    & Mean square   & F-ratio               \\
        \hline
        Between samples     & $SS_B$            & $k-1$                 & $MS_B$        & $\dfrac{MS_B}{MS_W}$  \\
        Within samples      & $SS_W$            & $n-k$                 & $MS_W$        &                       \\
        \hline
        Total               & $SS_T$            & $n-1$                 &               &                       \\
        \end{tabular}
        \end{center}
        \egroup
        The F-ratio forms the test statistic and the F-distribution is used to find the critical value. Note that $MS_B$ will always be larger than $MS_W$ so we always select the upper tail as the critical value.

        \begin{example}
        {   
            In a comparision of the cleaning action of four detergents, pieces of cloth were measured for whiteness after being washed by a particular detergent. The results were as follows:
            \begin{center}
            \begin{tabular}{c|c|c|c}
            A  & B  & C  & D  \\
            \hline
            77 & 74 & 73 & 76 \\
            81 & 66 & 78 & 85 \\
            61 & 58 & 57 & 77 \\
            76 &    & 69 & 64 \\
            69 &    & 63 &    \\
            \end{tabular}
            \end{center}
            Assuming the whiteness readings are normally distributed, with a common variance, test hypothesis that their is no diffrence between the four brands whiteness using a 5\% significance level.
        }

        \begin{step}{Hypothesis}
        $H_0$: no diffrence in the mean whiteness\\
        $H_1$: a diffrence in the mean whiteness\\
        \end{step}

        \begin{step}{Work out the sum of squares}
        \begin{center}
        \begin{tabular}{l|c|c|c|c|c}
                & A     & B     & C     & D     & Total \\
        \hline
        $n_i$   & 5     & 3     & 5     & 4     & 17    \\
        $T_i$   & 364   & 198   & 340   & 302   & 1204  \\
        \end{tabular}
        \end{center}

        \begin{align*}
        SS_T &= 77^2 + 81^2 + 61^2 + ... + 64^2 - \frac{1204^2}{17}\\
        &= 86362 - 85271.529...\\
        &= 1090.47\\
        \\
        SS_B &= (\frac{364^2}{5} + \frac{198^2}{3} + \frac{340^2}{5} + \frac{302^2}{4}) - \frac{1204^2}{17}\\
        &= 85488.2 - 85271.529...\\
        &= 216.67\\
        \\
        SS_W &= 1090.47 - 216.67\\
        &= 873.80
        \end{align*}
        \end{step}

        \begin{step}{Complete the ANOVA table}
        \begin{center}
        \begin{tabular}{l|c|c|c|c}
        Source of variation & Sum of squares    & Degrees of freedom    & Mean square   & F-ratio   \\
        \hline
        Between samples     & $216.67$          & $3$                   & $72.22$       & $1.07$    \\
        Within samples      & $873.80$          & $13$                  & $67.22$       &           \\
        \hline
        Total               & $1090.47$         & $16$                  &               &           \\
        \end{tabular}
        \end{center}
        \end{step}

        \begin{step}{Critical value}
        $$
        F_{(3, 13)}(0.95) = 3.411 
        $$
        \end{step}

        \begin{step}{Conclusion}
        $1.07 < 3.411$ so accept $H_0$, their is no evidence at the 5\% significance level to suggest that their is any diffrence between the four brands.
        \end{step}
        \end{example}

    \newpage
    \subsection{Two-way ANOVA}
        A two-way ANOVA is an extension to the one-way ANOVA test that takes into account a second factor. The second factor is the blocking factor (since this test requires a radomised block design) since it places the samples into blocks.
        $$
        x_{ij} - \mu_{ij} = \epsilon_{ij} \sim N(0, \sigma^2)
        $$
        where
        $$
        \mu_{ij} = \mu + \alpha_i + \beta_j
        $$
        where $\mu$ is the overall mean, $\alpha_i$ is the mean effect of the $i^{th}$ level of the row factor relative to $\mu$, $\beta_j$ is the mean effect of the $j^{th}$ level of the column factor relative to $\mu$ and $\epsilon_{ij}$ is the inherent random variation.\\
        \\
        The follwing notation and formule are used in the calculation of a two-way ANOVA test:
        \bgroup
        \def\arraystretch{2}
        \begin{center}
        \begin{tabular}{l|c|c}
        Description & Symbol & Value \\
        \hline
        Number of levels of row factor & $m$ & \\
        Number of levels of column factor & $n$ & \\
        Total number of observations & $mn$ & \\
        Observation in $ij^{th}$ cell & $x_{ij}$ & $i = 1, 2, ..., m$ \\
        & & $j = 1, 2, ..., n$  \\
        Sum of $n$ observations in the $i^{th}$ row & $R_i$ & $\sum_j{x_{ij}}$ \\
        Sum of $m$ observations in the $j^{th}$ row & $C_j$ & $\sum_i{x_{ij}}$ \\
        Sum of all $mn$ observations & $T$ & $\sum_i{\sum_j{x_{ij}}} = \sum_i{R_i} = \sum_j{R_j}$ \\
        \hline
        Total sum of squares & $SS_T$ & $\displaystyle\sum_i{\displaystyle\sum_j{x_{ij}^2}} - \frac{T^2}{mn}$ \\
        Between rows sum of squares & $SS_R$ & $\displaystyle\sum_i{\frac{R_i^2}{n}} - \frac{T^2}{mn}$ \\
        Between column sum of squares & $SS_C$ & $\displaystyle\sum_i{\frac{C_j^2}{m}} - \frac{T^2}{mn}$ \\
        Error (residual) sum of squares & $SS_E$ & $SS_T - SS_R - SS_C$ \\
        \hline
        Between row mean squares & $MS_R$ & $\displaystyle\frac{SS_R}{n - 1}$ \\
        Between column mean squares & $MS_C$ & $\displaystyle\frac{SS_C}{m - 1}$ \\
        Error (residual) mean squares & $MS_E$ & $\displaystyle\frac{SS_E}{mn - 1}$ \\
        \end{tabular}
        \end{center}
        \egroup
        \noindent
        
        Its convient to lay out a two-way ANOVA test in a table such as:
        \bgroup
        \def\arraystretch{2}
        \begin{center}
        \begin{tabular}{l|c|c|c|c}
        Source of variation & Sum of squares    & Degrees of freedom    & Mean square   & F-ratio               \\
        \hline
        Between rows        & $SS_R$            & $m-1$                 & $MS_R$        & $\dfrac{MS_R}{MS_E}$  \\
        Between columns     & $SS_C$            & $n-1$                 & $MS_C$        & $\dfrac{MS_C}{MS_E}$  \\
        Error (residual)    & $SS_E$            & $(m-1)(n-1)$          & $MS_E$        &                       \\
        \hline
        Total               & $SS_T$            & $mn-1$                &               &                       \\
        \end{tabular}
        \end{center}
        \egroup

        \begin{example}
        {
            Test at a 1\% significance level, that their is no diffrence between the four compilers and was the use of the program as a blocking factor worthwhile.

            \begin{center}
            \begin{tabular}{c|c|c|c|c}
            & \multicolumn{4}{c}{Compiler} \\
            Program & 1         & 2         & 3         & 4         \\
            \hline
            A       & $29.21$   & $28.25$   & $28.20$   & $28.62$   \\
            B       & $26.18$   & $26.02$   & $26.22$   & $25.56$   \\
            C       & $30.91$   & $30.18$   & $30.52$   & $30.09$   \\
            D       & $25.14$   & $25.26$   & $25.20$   & $25.02$   \\
            E       & $26.16$   & $25.14$   & $25.26$   & $25.46$   \\
            \end{tabular}
            \end{center}
        }

        \begin{step}{Hypothesis}
        $H_0$: No effect on compilation times due to compilers\\
        $H_1$: An effect on compilation times due to compilers\\
        \end{step}

        \begin{step}{Find the row and column totals}
        \begin{center}
        \begin{tabular}{c|cccc|c|c}
                            & \multicolumn{4}{c}{Compiler}                  & Row totals    &           \\
        Program             & 1         & 2         & 3         & 4         & $T_i$         & $n_i$     \\
        \hline          
        A                   & $29.21$   & $28.25$   & $28.20$   & $28.62$   & $114.28$      & 4         \\
        B                   & $26.18$   & $26.02$   & $26.22$   & $25.56$   & $103.98$      & 4         \\
        C                   & $30.91$   & $30.18$   & $30.52$   & $30.09$   & $121.70$      & 4         \\
        D                   & $25.14$   & $25.26$   & $25.20$   & $25.02$   & $100.62$      & 4         \\
        E                   & $26.16$   & $25.14$   & $25.26$   & $25.46$   & $102.02$      & 4         \\
        \hline
        Column totals $T_j$ & $137.60$  & $134.85$  & $135.40$  & $134.75$  & $T = 542.60$  &           \\
        \hline
        $n_j$               & $5$       & $5$       & $5$       & $5$       &               & $mn = 20$ \\
        \end{tabular}
        \end{center}
        \end{step}

        \begin{step}{Find the sum of squares}
        \begin{align*}
        SS_T &= (29.21^2 + 28.25^2 + ... + 25.46^2) - \frac{542.60^2}{20} \\
        &= 14805.7768 - 14720.738\\
        &= 85.0388\\
        \\
        SS_R &= \left(\frac{114.28^2}{4} + \frac{103.98^2}{4} + \frac{121.70^2}{4} + \frac{100.62^2}{4} + \frac{102.02^2}{4}\right) - \frac{542.60^2}{20}\\
        &= 83.0404\\
        \\
        SS_C &= \left(\frac{137.60^2}{5} + \frac{134.85^2}{5} + \frac{135.40^2}{5} + \frac{134.75^2}{5}\right) - \frac{542.60^2}{20}\\
        &= 1.063\\
        \\
        SS_E &= 85.0388 - 83.0404 - 1.063\\
        &= 0.9354
        \end{align*}
        \end{step}

        \begin{step}{Complete the ANOVA table}
        \begin{center}
        \begin{tabular}{l|c|c|c|c}
        Source of variation & Sum of squares    & Degrees of freedom    & Mean square   & F-ratio       \\
        \hline
        Between rows        & $83.0404$         & $4$                   & $20.7601$     & $266.33$      \\
        Between columns     & $1.063$           & $3$                   & $0.3543$      & $4.55$        \\
        Error (residual)    & $0.9354$          & $12$                  & $0.07795$     &               \\
        \hline
        Total               & $85.0388$         & $11$                  &               &               \\
        \end{tabular}
        \end{center}
        \end{step}

        \begin{step}{Critical value}
        $$
        F_{(3, 12)}(0.99) = 5.953
        $$
        \end{step}

        \begin{step}{Conclusion}
        $4.55 < 5.953$ so accept $H_0$, thus their is no evidence at the 1\% significance level to suggest a diffrence in compilation times between the four compilers.
        \end{step}

        \begin{step}{Was the blocking factor worthwhile?}
        \begin{itemize}
        \item The variation between programs accounted for $\dfrac{83.0404}{85.0388} \times 100 = 97.65\%$ of the variation (which most would have gone into $SS_E$ had the blocking factor not been used).
        \item $F_R = 266.33$ which would have been significant at any level.
        \end{itemize}
        \end{step}

        \end{example}

    \newpage
    \subsection{Latin square designs}
        Consider a randomised block design in which:
        $$ \text{number of blocks} = \text{number of treatments} = n $$
        This is equivilent to a two-way ANOVA in which:
        $$ \text{number of rows} = \text{number of columns} = n $$
        So the total number of observations is $n^2$.\\
        \\
        It is possible to intoduce a second blocking factor (with $n$ levels) without increasing the number of observations to $n^3$ with the following model:
        $$
        x_{ij(k)} - \mu_{ij(k)} = \epsilon_{ij(k)} \sim N(0, \sigma^2)
        $$
        where 
        \begin{itemize}
        \item $x_{ij(k)}$ is the observation in the $i^{th}$ row, $j^{th}$ column with the letter $k$
        \item $\mu$ is the overall mean
        \item $\alpha_i$ is the mean effect of the $i^{th}$ level of row factor relative to $\mu$
        \item $\beta_j$ is the mean effect of the $j^{th}$ level of column factor relative to $\mu$
        \item $\gamma_k$ is the mean effect of the $k^{th}$ level of letter factor relative to $\mu$
        \item $\epsilon_{ij(k)}$ is the inherent random variation 
        \end{itemize}

        \begin{example}
        {
            In a comparision of three types of fuels (A, B and C), three makes of cars (1, 2 and 3), were used. Each car was driven at a speed of $50 km h^-1$, $75 km h^-1$ and $100 km h^-1$ around a track. The distrance travelled from depleting a full tank was recorded.
        
            \begin{center}
            \begin{tabular}{c|c|c|c}
            Car & Speed & Fuel  & Distance  \\
            1   & 50    & B     & 347.8     \\
            1   & 75    & C     & 331.4     \\
            1   & 100   & A     & 275.8     \\
            2   & 50    & A     & 365.4     \\
            2   & 100   & B     & 339.8     \\
            2   & 150   & C     & 298.9     \\
            3   & 50    & C     & 318.9     \\
            3   & 100   & A     & 302.2     \\
            3   & 150   & B     & 271.8     \\
            \end{tabular}
            \end{center}

            Investigate the diffrence between the three petrols.
        }

        \begin{step}{Rearrange the data into a latin square}
        \begin{center}
        \begin{tabular}{c|ccc|c|c}
                        & \multicolumn{3}{c}{Speed}         &           &           \\
        Car             & 50        & 75        & 100       & Row Total & $n_i$     \\
        \hline
        1               & B $347.8$ & C $331.4$ & A $275.8$ & $955.0$       & 3     \\
        2               & A $365.4$ & B $339.8$ & C $298.9$ & $1004.1$      & 3     \\
        3               & C $318.9$ & A $302.2$ & B $271.8$ & $892.9$       & 3     \\
        \hline
        Column total    & $1032.1$  & $973.4$   & $846.5$   & $T = 2852.0$  &       \\
        \hline
        $n_j$           & 3         & 3         & 3         &               & n = 9 \\
        \end{tabular}
        \end{center}

        \begin{align*}
        L_A &= 943.4\\
        L_B &= 959.4\\
        L_C &= 949.2
        \end{align*}
        \end{step}

        \begin{step}{Find the sum of squares}
        \begin{align*}
        SS_T &= (347.8^2 + 331.4^2 + ... + 271.8^2) - \frac{2852.0^2}{9}\\
        &= 912076.14 - 903767.11\\
        &= 8309.03\\
        \\
        SS_R &= (\frac{955.0^2}{3} + \frac{1004.1^2}{3} + \frac{892.9^2}{3}) - 903767.11\\
        &= 2070.30\\
        \\
        SS_C &= (\frac{1032.1^2}{3} + \frac{973.4^2}{3} + \frac{846.5^2}{3}) - 903767.11\\
        &= 5999.63\\
        \\
        SS_L &= (\frac{943.4^2}{3} + \frac{959.4^2}{3} + \frac{949.2^2}{3}) - 903767.11\\
        &= 43.74\\
        \\
        SS_E &= 8309.03 - 2070.30 - 5999.63 - 43.74
        &= 195.36
        \end{align*}
        \end{step}

        \begin{step}{Contruct ANOVA table}
        \begin{center}
        \begin{tabular}{l|c|c|c|c}
        Source of variation & Sum of squares    & Degrees of freedom    & Mean square   & F-ratio       \\
        \hline
        Between cars        & $2070.30$         & $2$                   & $1035.15$     & $10.60$       \\
        Between speeds      & $5999.63$         & $2$                   & $2999.81$     & $30.71$       \\
        Between brands      & $43.74$           & $2$                   & $21.87$       & $0.22$        \\
        Residual            & $0.9354$          & $2$                   & $97.68$       &               \\
        \hline
        Total               & $8309.03$         & $8$                   &               &               \\
        \end{tabular}
        \end{center}
        \end{step}

        \begin{step}{Critical value}
        $$
        F_{(2, 2)}(0.95) = 19.00
        $$
        \end{step}

        \begin{step}{Conclusion}
        \begin{itemize}
        \item $0.22 < 19.00$ so their is no evidence that fuel consumption is dependent on the brand of fuel
        \item $30.71 > 19.00$ so the speed of cars proved to be signigicant
        \item $10.60 < 19.00$ so the car was not suggnificant, however it did reduce the residual sum of squares 
        \end{itemize}
        \end{step}

        \end{example}

\newpage
\section{Statistical Process Control}

\newpage
\section{Acceptance Sampling}
